{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Basic Overview\n",
    "The objective is to build a linear regression model by adding and transforming predictors step by step.\n",
    "\n",
    "Comments/criticisms/appreciations are greatly accepted and appreciated. Do not be shy and send me an email at babinu@gmail.com !\n",
    "\n",
    "Source of data : https://www.kaggle.com/c/house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys    \n",
    "sys.path.append('../../common_routines/')\n",
    "import numpy as np\n",
    "from relevant_functions import\\\n",
    "    evaluate_model_score_given_predictions,\\\n",
    "    evaluate_model_score,\\\n",
    "    evaluate_neg_model_score,\\\n",
    "    cross_val_score_given_model,\\\n",
    "    fit_pipeline_and_cross_validate, \\\n",
    "    fit_pipeline_and_evaluate_on_validation_set, \\\n",
    "    print_model_stats_from_pipeline, \\\n",
    "    get_validated_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_train_data = pd.read_csv(\"../../input/train.csv\")\n",
    "test_data = pd.read_csv(\"../../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump alll the dataframes with one hot encoding.\n",
    "train_data_one_hot = pd.read_csv('../../cleaned_input/train_data_one_hot.csv')\n",
    "validation_data_one_hot = pd.read_csv('../../cleaned_input/validation_data_one_hot.to_csv')\n",
    "test_data_one_hot =pd.read_csv('../../cleaned_input/test_data_one_hot.csv')\n",
    "\n",
    "# Dump the data frames prior to taking the one hot encoding transformation.\n",
    "# Remember that we had handled the null values at the stage and hence the model\n",
    "# does not need to worry about the same.\n",
    "train_data = pd.read_csv('../../cleaned_input/train_data.csv')\n",
    "validation_data = pd.read_csv('../../cleaned_input/validation_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building simple models.\n",
    "\n",
    "Now that we have finally taken care of data, let us go to the next step by building simple models. This way, we will be able to appreciate the contribution of every variable and will learn step by step model building !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We build a model after transforming response.\n",
    "\n",
    "We could build a linear model predicting the sale price directly and then judge how good it is, by evaluating using the logarithm of the sale price. Alternatively, we could take the logarithm of the sale price at first and use that as the predictor variable. \n",
    "\n",
    "We will be using the second approach as that looks more appropriate from the data plots for SalePrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add LogMiscVal as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4022329940035444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import linear_model\n",
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot , \n",
    "    X_columns=['LogMiscVal'])[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.000000\n",
       "5       6.552508\n",
       "6       0.000000\n",
       "7       5.860786\n",
       "8       0.000000\n",
       "9       0.000000\n",
       "10      0.000000\n",
       "11      0.000000\n",
       "12      0.000000\n",
       "13      0.000000\n",
       "14      0.000000\n",
       "15      0.000000\n",
       "16      6.552508\n",
       "17      6.216606\n",
       "18      0.000000\n",
       "19      0.000000\n",
       "20      0.000000\n",
       "21      0.000000\n",
       "22      0.000000\n",
       "23      0.000000\n",
       "24      0.000000\n",
       "25      0.000000\n",
       "26      0.000000\n",
       "27      0.000000\n",
       "28      0.000000\n",
       "29      0.000000\n",
       "          ...   \n",
       "1065    0.000000\n",
       "1066    0.000000\n",
       "1067    0.000000\n",
       "1068    0.000000\n",
       "1069    0.000000\n",
       "1070    0.000000\n",
       "1071    0.000000\n",
       "1072    0.000000\n",
       "1073    0.000000\n",
       "1074    0.000000\n",
       "1075    0.000000\n",
       "1076    6.216606\n",
       "1077    0.000000\n",
       "1078    0.000000\n",
       "1079    0.000000\n",
       "1080    0.000000\n",
       "1081    0.000000\n",
       "1082    0.000000\n",
       "1083    6.552508\n",
       "1084    0.000000\n",
       "1085    0.000000\n",
       "1086    0.000000\n",
       "1087    0.000000\n",
       "1088    0.000000\n",
       "1089    0.000000\n",
       "1090    0.000000\n",
       "1091    0.000000\n",
       "1092    0.000000\n",
       "1093    0.000000\n",
       "1094    0.000000\n",
       "Name: LogMiscVal, Length: 1095, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_one_hot['LogMiscVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add LogGrLivArea as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27161716540345976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import linear_model\n",
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out categorical variables.\n",
    "\n",
    "Rather than dumping all the one hot encoded values of a categorical variable to the model, we try a slightly different approach here. \n",
    "\n",
    "We group the saleprices per category and try to see which of the categories , would result in a high average sale price. Depending on that we would come up with a synthetic indicator  variable that would be set to 1, if the category belonged to the one corresponding to the  high saleprice and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column : MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_count_per_group(train_data, group_col):\n",
    "    results_df = pd.DataFrame(train_data[['SalePrice', group_col]].groupby([group_col]).size())\n",
    "    results_df['mean_SalePrice'] =  train_data[['SalePrice', group_col]].groupby(group_col).SalePrice.mean()\n",
    "    results_df['mean_LogSalePrice'] =  train_data[['LogSalePrice', group_col]].groupby(group_col).LogSalePrice.mean()\n",
    "\n",
    "  \n",
    "    # Added later one.\n",
    "    if 'LogSalePricePerSqFeet' in train_data.columns:\n",
    "        results_df['mean_LogSalePricePerSqFeet'] =  \\\n",
    "            train_data[['LogSalePricePerSqFeet', group_col]].groupby(group_col).LogSalePricePerSqFeet.mean()    \n",
    "        results_df.columns = ['Count', 'mean_SalePrice', 'mean_LogSalePrice', 'mean_LogSalePricePerSqFeet']\n",
    "    else:\n",
    "        results_df.columns = ['Count', 'mean_SalePrice', 'mean_LogSalePrice']\n",
    "    results_df['percent_total_size'] = results_df['Count'] * 100.0/len(train_data)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'MSSubClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>232</td>\n",
       "      <td>241847.021552</td>\n",
       "      <td>12.349193</td>\n",
       "      <td>21.187215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>14</td>\n",
       "      <td>200392.857143</td>\n",
       "      <td>12.099105</td>\n",
       "      <td>1.278539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>68</td>\n",
       "      <td>198945.705882</td>\n",
       "      <td>12.166660</td>\n",
       "      <td>6.210046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>403</td>\n",
       "      <td>184686.218362</td>\n",
       "      <td>12.048144</td>\n",
       "      <td>36.803653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>38</td>\n",
       "      <td>168185.526316</td>\n",
       "      <td>12.009529</td>\n",
       "      <td>3.470320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>41</td>\n",
       "      <td>166279.463415</td>\n",
       "      <td>11.949679</td>\n",
       "      <td>3.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>15</td>\n",
       "      <td>151113.333333</td>\n",
       "      <td>11.918590</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>140537.780000</td>\n",
       "      <td>11.800060</td>\n",
       "      <td>9.132420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>49</td>\n",
       "      <td>138363.938776</td>\n",
       "      <td>11.804102</td>\n",
       "      <td>4.474886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>39</td>\n",
       "      <td>133278.897436</td>\n",
       "      <td>11.779705</td>\n",
       "      <td>3.561644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>24</td>\n",
       "      <td>130745.833333</td>\n",
       "      <td>11.743055</td>\n",
       "      <td>2.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>11.671084</td>\n",
       "      <td>0.273973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12</td>\n",
       "      <td>108591.666667</td>\n",
       "      <td>11.579033</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50</td>\n",
       "      <td>95819.020000</td>\n",
       "      <td>11.436689</td>\n",
       "      <td>4.566210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>7</td>\n",
       "      <td>92285.714286</td>\n",
       "      <td>11.407724</td>\n",
       "      <td>0.639269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "MSSubClass                                                              \n",
       "60            232   241847.021552          12.349193           21.187215\n",
       "75             14   200392.857143          12.099105            1.278539\n",
       "120            68   198945.705882          12.166660            6.210046\n",
       "20            403   184686.218362          12.048144           36.803653\n",
       "80             38   168185.526316          12.009529            3.470320\n",
       "70             41   166279.463415          11.949679            3.744292\n",
       "85             15   151113.333333          11.918590            1.369863\n",
       "50            100   140537.780000          11.800060            9.132420\n",
       "160            49   138363.938776          11.804102            4.474886\n",
       "90             39   133278.897436          11.779705            3.561644\n",
       "190            24   130745.833333          11.743055            2.191781\n",
       "40              3   121500.000000          11.671084            0.273973\n",
       "45             12   108591.666667          11.579033            1.095890\n",
       "30             50    95819.020000          11.436689            4.566210\n",
       "180             7    92285.714286          11.407724            0.639269"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_column_train_validation_test(train_data_one_hot,\n",
    "                                           validation_data_one_hot,\n",
    "                                           test_data_one_hot,\n",
    "                                           target_col,\n",
    "                                           source_cols):\n",
    "\n",
    "    train_data_one_hot[target_col] = 0\n",
    "    validation_data_one_hot[target_col] = 0\n",
    "    test_data_one_hot[target_col] = 0\n",
    "    \n",
    "    for col in source_cols:\n",
    "        train_data_one_hot[target_col] += train_data_one_hot[col]\n",
    "        validation_data_one_hot[target_col] += validation_data_one_hot[col]\n",
    "        test_data_one_hot[target_col] += test_data_one_hot[col]        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test(train_data_one_hot, validation_data_one_hot, test_data_one_hot,\n",
    "                                      'MSSubClass_60_75_120_20', \n",
    "                                      ['MSSubClass_120', 'MSSubClass_60', 'MSSubClass_20', 'MSSubClass_75'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23998906193907085"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import linear_model\n",
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another thought ?\n",
    "\n",
    "Someone might claim that the average sale price for that zone (in logarithmic terms) would measure the importance of that zone and hence that might be a better indicator than the one used above. Let us see if that is the case.\n",
    "\n",
    "NOTE : I would expect this to be an inferior indicator than the one which we used above, since the values simply look too close to each other and do not look to capture the differences in subclasses sufficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_to_LogSalePrice = dict(zip(results_df.index, results_df.mean_LogSalePrice)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: 12.04814412706041,\n",
       " 30: 11.43668923670398,\n",
       " 40: 11.671084169224912,\n",
       " 45: 11.579032983343444,\n",
       " 50: 11.800059519050276,\n",
       " 60: 12.349192704221739,\n",
       " 70: 11.949678887429084,\n",
       " 75: 12.09910527148951,\n",
       " 80: 12.009529285935356,\n",
       " 85: 11.918589623636617,\n",
       " 90: 11.779705171526395,\n",
       " 120: 12.166660247259609,\n",
       " 160: 11.80410228120793,\n",
       " 180: 11.407723715624837,\n",
       " 190: 11.743054692745964}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_to_LogSalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['MSSubClass_Val'] = train_data['MSSubClass'].apply (lambda x : subclass_to_LogSalePrice.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25140820156722005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : As expected , this variable does not look to give us a better result and hence we stick with the earlier one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column : MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSZoning</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FV</th>\n",
       "      <td>53</td>\n",
       "      <td>216483.132075</td>\n",
       "      <td>12.256738</td>\n",
       "      <td>4.840183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RL</th>\n",
       "      <td>859</td>\n",
       "      <td>191861.142026</td>\n",
       "      <td>12.090554</td>\n",
       "      <td>78.447489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>12</td>\n",
       "      <td>133994.500000</td>\n",
       "      <td>11.771509</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>162</td>\n",
       "      <td>123783.141975</td>\n",
       "      <td>11.671673</td>\n",
       "      <td>14.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C (all)</th>\n",
       "      <td>9</td>\n",
       "      <td>75208.888889</td>\n",
       "      <td>11.116607</td>\n",
       "      <td>0.821918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "MSZoning                                                              \n",
       "FV           53   216483.132075          12.256738            4.840183\n",
       "RL          859   191861.142026          12.090554           78.447489\n",
       "RH           12   133994.500000          11.771509            1.095890\n",
       "RM          162   123783.141975          11.671673           14.794521\n",
       "C (all)       9    75208.888889          11.116607            0.821918"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test(train_data_one_hot,\n",
    "                                       validation_data_one_hot,\n",
    "                                       test_data_one_hot,\n",
    "                                       'MSZoning_FV_RL',\n",
    "                                       ['MSZoning_FV', 'MSZoning_RL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23218002510204933"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import linear_model\n",
    "fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'MSZoning_FV_RL'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add OverallQual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>426924.250000</td>\n",
       "      <td>12.915566</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>370448.594595</td>\n",
       "      <td>12.798459</td>\n",
       "      <td>3.378995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125</td>\n",
       "      <td>276423.744000</td>\n",
       "      <td>12.505475</td>\n",
       "      <td>11.415525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>242</td>\n",
       "      <td>208365.752066</td>\n",
       "      <td>12.224535</td>\n",
       "      <td>22.100457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>279</td>\n",
       "      <td>161053.229391</td>\n",
       "      <td>11.964026</td>\n",
       "      <td>25.479452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>132138.312081</td>\n",
       "      <td>11.769357</td>\n",
       "      <td>27.214612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>108032.373494</td>\n",
       "      <td>11.552726</td>\n",
       "      <td>7.579909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>89298.333333</td>\n",
       "      <td>11.352054</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50150.000000</td>\n",
       "      <td>10.798804</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47655.500000</td>\n",
       "      <td>10.737025</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "OverallQual                                                              \n",
       "10              12   426924.250000          12.915566            1.095890\n",
       "9               37   370448.594595          12.798459            3.378995\n",
       "8              125   276423.744000          12.505475           11.415525\n",
       "7              242   208365.752066          12.224535           22.100457\n",
       "6              279   161053.229391          11.964026           25.479452\n",
       "5              298   132138.312081          11.769357           27.214612\n",
       "4               83   108032.373494          11.552726            7.579909\n",
       "3               15    89298.333333          11.352054            1.369863\n",
       "1                2    50150.000000          10.798804            0.182648\n",
       "2                2    47655.500000          10.737025            0.182648"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18337479641918253"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add OverallCond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'OverallCond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>232800.000000</td>\n",
       "      <td>12.281401</td>\n",
       "      <td>1.278539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>616</td>\n",
       "      <td>204137.683442</td>\n",
       "      <td>12.149918</td>\n",
       "      <td>56.255708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56</td>\n",
       "      <td>155671.875000</td>\n",
       "      <td>11.913001</td>\n",
       "      <td>5.114155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>151</td>\n",
       "      <td>155629.172185</td>\n",
       "      <td>11.903480</td>\n",
       "      <td>13.789954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192</td>\n",
       "      <td>154531.083333</td>\n",
       "      <td>11.887697</td>\n",
       "      <td>17.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>141986.400000</td>\n",
       "      <td>11.593353</td>\n",
       "      <td>0.456621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>124027.609756</td>\n",
       "      <td>11.677698</td>\n",
       "      <td>3.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>98333.421053</td>\n",
       "      <td>11.392669</td>\n",
       "      <td>1.735160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61000.000000</td>\n",
       "      <td>11.018629</td>\n",
       "      <td>0.091324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "OverallCond                                                              \n",
       "9               14   232800.000000          12.281401            1.278539\n",
       "5              616   204137.683442          12.149918           56.255708\n",
       "8               56   155671.875000          11.913001            5.114155\n",
       "7              151   155629.172185          11.903480           13.789954\n",
       "6              192   154531.083333          11.887697           17.534247\n",
       "2                5   141986.400000          11.593353            0.456621\n",
       "4               41   124027.609756          11.677698            3.744292\n",
       "3               19    98333.421053          11.392669            1.735160\n",
       "1                1    61000.000000          11.018629            0.091324"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18081723445902273"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual', 'OverallCond'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : Can't we combine Qverall quality and condition variables ? Is it necessary to have 2 separate variables here ?\n",
    "\n",
    "We do look to be some predictive power here, so let us keep both of them. However, at some point in our model building, we may find that the predictive power associated with OverallCond is actually given by other variables as well and hence we do not need it any longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add column Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'Neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NridgHt</th>\n",
       "      <td>64</td>\n",
       "      <td>321781.359375</td>\n",
       "      <td>12.637217</td>\n",
       "      <td>5.844749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StoneBr</th>\n",
       "      <td>22</td>\n",
       "      <td>320657.954545</td>\n",
       "      <td>12.617717</td>\n",
       "      <td>2.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoRidge</th>\n",
       "      <td>27</td>\n",
       "      <td>318553.333333</td>\n",
       "      <td>12.637571</td>\n",
       "      <td>2.465753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timber</th>\n",
       "      <td>28</td>\n",
       "      <td>243325.964286</td>\n",
       "      <td>12.368274</td>\n",
       "      <td>2.557078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veenker</th>\n",
       "      <td>8</td>\n",
       "      <td>240062.500000</td>\n",
       "      <td>12.340842</td>\n",
       "      <td>0.730594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somerst</th>\n",
       "      <td>65</td>\n",
       "      <td>227413.692308</td>\n",
       "      <td>12.303509</td>\n",
       "      <td>5.936073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClearCr</th>\n",
       "      <td>24</td>\n",
       "      <td>214159.666667</td>\n",
       "      <td>12.245548</td>\n",
       "      <td>2.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crawfor</th>\n",
       "      <td>34</td>\n",
       "      <td>199796.294118</td>\n",
       "      <td>12.156602</td>\n",
       "      <td>3.105023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CollgCr</th>\n",
       "      <td>114</td>\n",
       "      <td>195479.008772</td>\n",
       "      <td>12.151860</td>\n",
       "      <td>10.410959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blmngtn</th>\n",
       "      <td>14</td>\n",
       "      <td>194023.357143</td>\n",
       "      <td>12.165725</td>\n",
       "      <td>1.278539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWAmes</th>\n",
       "      <td>51</td>\n",
       "      <td>190841.274510</td>\n",
       "      <td>12.137510</td>\n",
       "      <td>4.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>55</td>\n",
       "      <td>189854.527273</td>\n",
       "      <td>12.143467</td>\n",
       "      <td>5.022831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SawyerW</th>\n",
       "      <td>48</td>\n",
       "      <td>185224.833333</td>\n",
       "      <td>12.080635</td>\n",
       "      <td>4.383562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>35</td>\n",
       "      <td>161726.742857</td>\n",
       "      <td>11.970940</td>\n",
       "      <td>3.196347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWISU</th>\n",
       "      <td>18</td>\n",
       "      <td>147407.444444</td>\n",
       "      <td>11.885204</td>\n",
       "      <td>1.643836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAmes</th>\n",
       "      <td>166</td>\n",
       "      <td>146291.072289</td>\n",
       "      <td>11.869944</td>\n",
       "      <td>15.159817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPkVill</th>\n",
       "      <td>6</td>\n",
       "      <td>144500.000000</td>\n",
       "      <td>11.879205</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sawyer</th>\n",
       "      <td>58</td>\n",
       "      <td>138805.741379</td>\n",
       "      <td>11.827806</td>\n",
       "      <td>5.296804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blueste</th>\n",
       "      <td>2</td>\n",
       "      <td>137500.000000</td>\n",
       "      <td>11.826536</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OldTown</th>\n",
       "      <td>85</td>\n",
       "      <td>128986.576471</td>\n",
       "      <td>11.702858</td>\n",
       "      <td>7.762557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edwards</th>\n",
       "      <td>74</td>\n",
       "      <td>127836.486486</td>\n",
       "      <td>11.710861</td>\n",
       "      <td>6.757991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrkSide</th>\n",
       "      <td>41</td>\n",
       "      <td>123731.097561</td>\n",
       "      <td>11.662072</td>\n",
       "      <td>3.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrDale</th>\n",
       "      <td>11</td>\n",
       "      <td>104263.636364</td>\n",
       "      <td>11.546982</td>\n",
       "      <td>1.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDOTRR</th>\n",
       "      <td>30</td>\n",
       "      <td>98809.333333</td>\n",
       "      <td>11.429113</td>\n",
       "      <td>2.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeadowV</th>\n",
       "      <td>15</td>\n",
       "      <td>97120.000000</td>\n",
       "      <td>11.459026</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "Neighborhood                                                              \n",
       "NridgHt          64   321781.359375          12.637217            5.844749\n",
       "StoneBr          22   320657.954545          12.617717            2.009132\n",
       "NoRidge          27   318553.333333          12.637571            2.465753\n",
       "Timber           28   243325.964286          12.368274            2.557078\n",
       "Veenker           8   240062.500000          12.340842            0.730594\n",
       "Somerst          65   227413.692308          12.303509            5.936073\n",
       "ClearCr          24   214159.666667          12.245548            2.191781\n",
       "Crawfor          34   199796.294118          12.156602            3.105023\n",
       "CollgCr         114   195479.008772          12.151860           10.410959\n",
       "Blmngtn          14   194023.357143          12.165725            1.278539\n",
       "NWAmes           51   190841.274510          12.137510            4.657534\n",
       "Gilbert          55   189854.527273          12.143467            5.022831\n",
       "SawyerW          48   185224.833333          12.080635            4.383562\n",
       "Mitchel          35   161726.742857          11.970940            3.196347\n",
       "SWISU            18   147407.444444          11.885204            1.643836\n",
       "NAmes           166   146291.072289          11.869944           15.159817\n",
       "NPkVill           6   144500.000000          11.879205            0.547945\n",
       "Sawyer           58   138805.741379          11.827806            5.296804\n",
       "Blueste           2   137500.000000          11.826536            0.182648\n",
       "OldTown          85   128986.576471          11.702858            7.762557\n",
       "Edwards          74   127836.486486          11.710861            6.757991\n",
       "BrkSide          41   123731.097561          11.662072            3.744292\n",
       "BrDale           11   104263.636364          11.546982            1.004566\n",
       "IDOTRR           30    98809.333333          11.429113            2.739726\n",
       "MeadowV          15    97120.000000          11.459026            1.369863"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1095.000000\n",
       "mean     181388.136986\n",
       "std       79728.891687\n",
       "min       34900.000000\n",
       "25%      130000.000000\n",
       "50%      163000.000000\n",
       "75%      214250.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test(train_data_one_hot, validation_data_one_hot, test_data_one_hot,\n",
    "                                       'Neighbourhood_Good',\n",
    "                                       ['Neighborhood_NridgHt', 'Neighborhood_StoneBr', \n",
    "                                        'Neighborhood_NoRidge', 'Neighborhood_Timber', \n",
    "                                        'Neighborhood_Veenker', 'Neighborhood_Somerst', \n",
    "                                        'Neighborhood_ClearCr', 'Neighborhood_Crawfor', \n",
    "                                        'Neighborhood_CollgCr', 'Neighborhood_Blmngtn',\n",
    "                                        'Neighborhood_NWAmes', 'Neighborhood_Gilbert', 'Neighborhood_SawyerW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17366550584852522"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual', 'OverallCond', 'Neighbourhood_Good'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : Again , does taking the logarithm of mean of the selling price for each neighbourhood and using that as the indicator value for each neighbourhood help ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_to_LogSalePrice = dict(zip(results_df.index, results_df.mean_LogSalePrice)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                     validation_data,\n",
    "                                                     test_data,\n",
    "                                                     train_data_one_hot,\n",
    "                                                     validation_data_one_hot,\n",
    "                                                     test_data_one_hot,\n",
    "                                                     target_col,\n",
    "                                                     source_col,\n",
    "                                                     given_dict):  \n",
    "  \n",
    "    train_data[target_col] = train_data[source_col].apply (lambda x : given_dict.get(x))\n",
    "    validation_data[target_col] = validation_data[source_col].apply (lambda x : given_dict.get(x))\n",
    "    test_data[target_col] = test_data[source_col].apply (lambda x : given_dict.get(x))    \n",
    "\n",
    "    train_data_one_hot[target_col] = train_data[target_col]\n",
    "    validation_data_one_hot[target_col] = validation_data[target_col]\n",
    "    test_data_one_hot[target_col] = test_data[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                 validation_data,\n",
    "                                                 test_data,\n",
    "                                                 train_data_one_hot,\n",
    "                                                 validation_data_one_hot,\n",
    "                                                 test_data_one_hot,\n",
    "                                                 'Neighborhood_Val',\n",
    "                                                 'Neighborhood',\n",
    "                                                 neighbourhood_to_LogSalePrice)                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual', 'OverallCond', 'Neighborhood_Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16071596412853448"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : This was a pleasant surprice. Let us delve into this more deeply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = my_pipeline.named_steps['linearregression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9241571949922722"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.02512502918356"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_one_hot['LogSalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45268743, 0.10927628, 0.09974205, 0.04102905, 0.40766989])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : From first glance ,we can see the following :\n",
    "\n",
    "(a) The magnitude of coefficients is much higher for LogGrLivArea and Neighborhood_Val , possibly because they are in the same logarithmic response scale as the predictor variable.\n",
    "(b) The intercept term is roughly 25% of the predictor variable, indicating that there is lot of improvement possible.\n",
    "\n",
    "However, there is an important caveat here. We have used the average values across the entire data, while doing cross validation, and hence the hold out sets used during cross validation are not 'fully held out' sets in strictest terms. So, before we proceed further, we need to make sure the performance is more or less the same, or completely held out validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(my_pipeline, validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual', 'OverallCond', 'Neighborhood_Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1624076804255766"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : As expected, we see a slight bump in the score, but thankfully it is still in the ballpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question regarding OverallQual and OverallCond ?\n",
    "\n",
    "Now, that we have seen how dramatically the model performance improved when we used the averge home prices as the value for a neighbourhood, can we do the same for OverallQual and OverallCond ? \n",
    "\n",
    "Putting it more clearly, rather than directly using the numerical values of these variables, can't we use the mean log sale price grouped per value of OverallQual (or OverallCond) and use that as a proxy for quality/ condition ?\n",
    "\n",
    "Let us see if this gives us any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50150.000000</td>\n",
       "      <td>10.798804</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47655.500000</td>\n",
       "      <td>10.737025</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>89298.333333</td>\n",
       "      <td>11.352054</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>108032.373494</td>\n",
       "      <td>11.552726</td>\n",
       "      <td>7.579909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>132138.312081</td>\n",
       "      <td>11.769357</td>\n",
       "      <td>27.214612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>279</td>\n",
       "      <td>161053.229391</td>\n",
       "      <td>11.964026</td>\n",
       "      <td>25.479452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>242</td>\n",
       "      <td>208365.752066</td>\n",
       "      <td>12.224535</td>\n",
       "      <td>22.100457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125</td>\n",
       "      <td>276423.744000</td>\n",
       "      <td>12.505475</td>\n",
       "      <td>11.415525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>370448.594595</td>\n",
       "      <td>12.798459</td>\n",
       "      <td>3.378995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>426924.250000</td>\n",
       "      <td>12.915566</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "OverallQual                                                              \n",
       "1                2    50150.000000          10.798804            0.182648\n",
       "2                2    47655.500000          10.737025            0.182648\n",
       "3               15    89298.333333          11.352054            1.369863\n",
       "4               83   108032.373494          11.552726            7.579909\n",
       "5              298   132138.312081          11.769357           27.214612\n",
       "6              279   161053.229391          11.964026           25.479452\n",
       "7              242   208365.752066          12.224535           22.100457\n",
       "8              125   276423.744000          12.505475           11.415525\n",
       "9               37   370448.594595          12.798459            3.378995\n",
       "10              12   426924.250000          12.915566            1.095890"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallQual_to_LogSalePrice = dict(zip(results_df.index, results_df.mean_LogSalePrice)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                 validation_data,\n",
    "                                                 test_data,\n",
    "                                                 train_data_one_hot,\n",
    "                                                 validation_data_one_hot,\n",
    "                                                 test_data_one_hot,\n",
    "                                                 'OverallQual_Val',\n",
    "                                                 'OverallQual',\n",
    "                                                 overallQual_to_LogSalePrice)                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1593692076533335\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual_Val', 'OverallCond', 'Neighborhood_Val'])\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : That looked decent. Let us see how it performs on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1620311693797422\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual_Val', 'OverallCond', 'Neighborhood_Val'])\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: This is rather miniscule on the validation set. Let us try the same with OverallCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                 validation_data,\n",
    "                                                 test_data,\n",
    "                                                 train_data_one_hot,\n",
    "                                                 validation_data_one_hot,\n",
    "                                                 test_data_one_hot,\n",
    "                                                 'OverallCond_Val',\n",
    "                                                 'OverallCond',\n",
    "                                                 overallQual_to_LogSalePrice)                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1593692076533335\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual_Val', 'OverallCond', 'Neighborhood_Val'])\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1620311693797422\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual_Val', 'OverallCond', 'Neighborhood_Val'])\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : As expected the results are a lot better while we do cross validation, since we are using the mean values obtained from the same sample, while the improvement in real out of sample testing is scarce. \n",
    "\n",
    "One reason is that OverallQual already was a numeric variable, and hence making it further numeric(in a sense, by using mean values) does not give us any real benefit. To make things simple, let us stick with the original numeric value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of road access.\n",
    "\n",
    "This should have an obvious effect on the home price. Let us see if that is the case !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', 'MSSubClass_60_75_120_20', 'OverallQual', 'OverallCond', 'Neighborhood_Val', 'Street_Grvl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16159832465959648\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16237566357698213\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : Does not provide us any benefit. Let us first have a look at the data (should have done this initially !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'Street')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grvl</th>\n",
       "      <td>5</td>\n",
       "      <td>118888.60000</td>\n",
       "      <td>11.573470</td>\n",
       "      <td>0.456621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pave</th>\n",
       "      <td>1090</td>\n",
       "      <td>181674.83211</td>\n",
       "      <td>12.027197</td>\n",
       "      <td>99.543379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "Street                                                              \n",
       "Grvl        5    118888.60000          11.573470            0.456621\n",
       "Pave     1090    181674.83211          12.027197           99.543379"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : This illustrates the point. The number of homes having street as Grvl is extremely small and hence this help us much in predictions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Home functionality.\n",
    "\n",
    "This is basic !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'Functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Typ</th>\n",
       "      <td>1017</td>\n",
       "      <td>184071.882006</td>\n",
       "      <td>12.041407</td>\n",
       "      <td>92.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mod</th>\n",
       "      <td>12</td>\n",
       "      <td>167333.333333</td>\n",
       "      <td>11.822068</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maj1</th>\n",
       "      <td>10</td>\n",
       "      <td>155377.400000</td>\n",
       "      <td>11.842128</td>\n",
       "      <td>0.913242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min2</th>\n",
       "      <td>25</td>\n",
       "      <td>149167.280000</td>\n",
       "      <td>11.875336</td>\n",
       "      <td>2.283105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min1</th>\n",
       "      <td>25</td>\n",
       "      <td>142798.000000</td>\n",
       "      <td>11.835228</td>\n",
       "      <td>2.283105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sev</th>\n",
       "      <td>1</td>\n",
       "      <td>129000.000000</td>\n",
       "      <td>11.767568</td>\n",
       "      <td>0.091324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maj2</th>\n",
       "      <td>5</td>\n",
       "      <td>85800.000000</td>\n",
       "      <td>11.316555</td>\n",
       "      <td>0.456621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "Functional                                                              \n",
       "Typ          1017   184071.882006          12.041407           92.876712\n",
       "Mod            12   167333.333333          11.822068            1.095890\n",
       "Maj1           10   155377.400000          11.842128            0.913242\n",
       "Min2           25   149167.280000          11.875336            2.283105\n",
       "Min1           25   142798.000000          11.835228            2.283105\n",
       "Sev             1   129000.000000          11.767568            0.091324\n",
       "Maj2            5    85800.000000          11.316555            0.456621"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we do not see possibility of much of a benefit as more than 92% of the homes have typical functionality.However , let us check if we can get something out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', \n",
    "              'MSSubClass_60_75_120_20', \n",
    "              'OverallQual', \n",
    "              'OverallCond', \n",
    "              'Neighborhood_Val', \n",
    "              'Functional_Typ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16028394663283646\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16218223743099083\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of benefit and hence moving on ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out LotShape\n",
    "\n",
    "Let us check if this helps !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'LotShape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotShape</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IR2</th>\n",
       "      <td>36</td>\n",
       "      <td>239407.444444</td>\n",
       "      <td>12.308040</td>\n",
       "      <td>3.287671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR3</th>\n",
       "      <td>4</td>\n",
       "      <td>219625.000000</td>\n",
       "      <td>12.133117</td>\n",
       "      <td>0.365297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR1</th>\n",
       "      <td>364</td>\n",
       "      <td>203873.071429</td>\n",
       "      <td>12.153877</td>\n",
       "      <td>33.242009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reg</th>\n",
       "      <td>691</td>\n",
       "      <td>166299.629522</td>\n",
       "      <td>11.941938</td>\n",
       "      <td>63.105023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "LotShape                                                              \n",
       "IR2          36   239407.444444          12.308040            3.287671\n",
       "IR3           4   219625.000000          12.133117            0.365297\n",
       "IR1         364   203873.071429          12.153877           33.242009\n",
       "Reg         691   166299.629522          11.941938           63.105023"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, there looks to be something here. There looks to be a clear demarcation between regular lots and others. Let us check if this adds any predictive power here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', \n",
    "              'MSSubClass_60_75_120_20', \n",
    "              'OverallQual', \n",
    "              'OverallCond', \n",
    "              'Neighborhood_Val', \n",
    "              'LotShape_Reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16007734733870088\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16219009333663442\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we do not see much of a benefit, let us see if creating synthetic indicator with grouped mean values, as we did for Neighborhood variable would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotShape_to_LogSalePrice = dict(zip(results_df.index, results_df.mean_LogSalePrice)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                 validation_data,\n",
    "                                                 test_data,\n",
    "                                                 train_data_one_hot,\n",
    "                                                 validation_data_one_hot,\n",
    "                                                 test_data_one_hot,\n",
    "                                                 'LotShape_Val',\n",
    "                                                 'OverallCond',\n",
    "                                                 lotShape_to_LogSalePrice)                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', \n",
    "              'MSSubClass_60_75_120_20', \n",
    "              'OverallQual', \n",
    "              'OverallCond', \n",
    "              'Neighborhood_Val', \n",
    "              'LotShape_Val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16071596412853448\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1624076804255766\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous indicator was better than this one. There looks a little bit of predictive power here, but not good enough to elicit our interest. Hence, let us move on !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Land Contour !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'LandContour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandContour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HLS</th>\n",
       "      <td>39</td>\n",
       "      <td>220733.564103</td>\n",
       "      <td>12.210646</td>\n",
       "      <td>3.561644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>28</td>\n",
       "      <td>204135.714286</td>\n",
       "      <td>12.099170</td>\n",
       "      <td>2.557078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lvl</th>\n",
       "      <td>986</td>\n",
       "      <td>180678.949290</td>\n",
       "      <td>12.023793</td>\n",
       "      <td>90.045662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bnk</th>\n",
       "      <td>42</td>\n",
       "      <td>146337.071429</td>\n",
       "      <td>11.834757</td>\n",
       "      <td>3.835616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "LandContour                                                              \n",
       "HLS             39   220733.564103          12.210646            3.561644\n",
       "Low             28   204135.714286          12.099170            2.557078\n",
       "Lvl            986   180678.949290          12.023793           90.045662\n",
       "Bnk             42   146337.071429          11.834757            3.835616"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of properties are flat, and hence we do not be getting much sense from the use of this data !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'Utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AllPub</th>\n",
       "      <td>1094</td>\n",
       "      <td>181428.254113</td>\n",
       "      <td>12.025302</td>\n",
       "      <td>99.908676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoSeWa</th>\n",
       "      <td>1</td>\n",
       "      <td>137500.000000</td>\n",
       "      <td>11.831379</td>\n",
       "      <td>0.091324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "Utilities                                                              \n",
       "AllPub      1094   181428.254113          12.025302           99.908676\n",
       "NoSeWa         1   137500.000000          11.831379            0.091324"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion is obvious !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'LotConfig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotConfig</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CulDSac</th>\n",
       "      <td>70</td>\n",
       "      <td>217030.242857</td>\n",
       "      <td>12.222853</td>\n",
       "      <td>6.392694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corner</th>\n",
       "      <td>204</td>\n",
       "      <td>179629.906863</td>\n",
       "      <td>12.024583</td>\n",
       "      <td>18.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inside</th>\n",
       "      <td>786</td>\n",
       "      <td>178854.849873</td>\n",
       "      <td>12.007129</td>\n",
       "      <td>71.780822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR2</th>\n",
       "      <td>33</td>\n",
       "      <td>177832.727273</td>\n",
       "      <td>12.039213</td>\n",
       "      <td>3.013699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR3</th>\n",
       "      <td>2</td>\n",
       "      <td>167500.000000</td>\n",
       "      <td>12.000130</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "LotConfig                                                              \n",
       "CulDSac       70   217030.242857          12.222853            6.392694\n",
       "Corner       204   179629.906863          12.024583           18.630137\n",
       "Inside       786   178854.849873          12.007129           71.780822\n",
       "FR2           33   177832.727273          12.039213            3.013699\n",
       "FR3            2   167500.000000          12.000130            0.182648"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reasonable number of the properties look to be coming in insids lots. Though we would not expected much , let us still see if this information would yield us something useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', \n",
    "              'MSSubClass_60_75_120_20', \n",
    "              'OverallQual', \n",
    "              'OverallCond', \n",
    "              'Neighborhood_Val', \n",
    "              'LotConfig_Inside']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16075783908320504\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1621394903119038\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there does not look to be anything much here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LandSlope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'LandSlope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sev</th>\n",
       "      <td>11</td>\n",
       "      <td>203357.272727</td>\n",
       "      <td>12.113266</td>\n",
       "      <td>1.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mod</th>\n",
       "      <td>48</td>\n",
       "      <td>198929.562500</td>\n",
       "      <td>12.093006</td>\n",
       "      <td>4.383562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gtl</th>\n",
       "      <td>1036</td>\n",
       "      <td>180342.143822</td>\n",
       "      <td>12.021044</td>\n",
       "      <td>94.611872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count  mean_SalePrice  mean_LogSalePrice  percent_total_size\n",
       "LandSlope                                                              \n",
       "Sev           11   203357.272727          12.113266            1.004566\n",
       "Mod           48   198929.562500          12.093006            4.383562\n",
       "Gtl         1036   180342.143822          12.021044           94.611872"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_SalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much point in moving forward here, as a huge majority (more than 94%) of the plots have a gentle slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditions.\n",
    "\n",
    "Let us have a look at the condition variables here. There are 2 variables here , indicating that we can have more than one condition for a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Norm', 'Feedr', 'PosN', 'Artery', 'RRAe', 'RRNn', 'RRAn', 'PosA',\n",
       "       'RRNe'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Condition1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Norm', 'Artery', 'RRNn', 'Feedr', 'PosN', 'PosA', 'RRAn'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Condition2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check those cases when we have a genuine case of 2 conditions, that is when one of the conditions is not 'Normal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRNn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>532</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>549</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRNn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>584</td>\n",
       "      <td>Artery</td>\n",
       "      <td>PosA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>590</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>975</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1004</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRAn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Condition1 Condition2\n",
       "29      30      Feedr       RRNn\n",
       "63      64       RRAn      Feedr\n",
       "184    185       RRAn      Feedr\n",
       "531    532       RRNn      Feedr\n",
       "548    549      Feedr       RRNn\n",
       "583    584     Artery       PosA\n",
       "589    590       RRAn      Feedr\n",
       "974    975       RRAn      Feedr\n",
       "1003  1004      Feedr       RRAn"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(train_data['Condition1'] != 'Norm') & \n",
    "           (train_data['Condition2'] != 'Norm') &\n",
    "           (train_data['Condition1'] != train_data['Condition2'])]\\\n",
    "[['Id', 'Condition1', 'Condition2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number looks too few. Let us check those cases when both conditions are not 'Normal'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Artery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRNn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>PosA</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>207</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>223</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>RRNe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>900</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>911</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>922</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>923</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>928</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>933</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>935</td>\n",
       "      <td>PosA</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>962</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>966</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>975</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>980</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>987</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>992</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>PosA</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1003</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1004</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1015</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1027</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1029</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1042</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1045</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1053</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1064</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>1072</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1073</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1082</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1094</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Condition1 Condition2\n",
       "1        2      Feedr       Norm\n",
       "7        8       PosN       Norm\n",
       "8        9     Artery       Norm\n",
       "9       10     Artery     Artery\n",
       "18      19       RRAe       Norm\n",
       "29      30      Feedr       RRNn\n",
       "30      31      Feedr       Norm\n",
       "52      53       RRNn       Norm\n",
       "60      61       RRAe       Norm\n",
       "63      64       RRAn      Feedr\n",
       "66      67       PosA       Norm\n",
       "68      69     Artery       Norm\n",
       "88      89      Feedr      Feedr\n",
       "108    109     Artery       Norm\n",
       "127    128      Feedr       Norm\n",
       "128    129       PosN       Norm\n",
       "142    143     Artery       Norm\n",
       "144    145       RRAe       Norm\n",
       "155    156     Artery       Norm\n",
       "170    171      Feedr       Norm\n",
       "182    183     Artery       Norm\n",
       "184    185       RRAn      Feedr\n",
       "185    186     Artery       Norm\n",
       "188    189      Feedr       Norm\n",
       "197    198     Artery       Norm\n",
       "202    203     Artery       Norm\n",
       "206    207       RRAe       Norm\n",
       "222    223       RRAn       Norm\n",
       "228    229      Feedr       Norm\n",
       "237    238       RRNe       Norm\n",
       "...    ...        ...        ...\n",
       "899    900      Feedr       Norm\n",
       "910    911      Feedr       Norm\n",
       "921    922      Feedr       Norm\n",
       "922    923       RRAn       Norm\n",
       "927    928      Feedr       Norm\n",
       "932    933       RRNn       Norm\n",
       "934    935       PosA       Norm\n",
       "941    942       RRNn       Norm\n",
       "961    962       PosN       Norm\n",
       "965    966       RRAn       Norm\n",
       "974    975       RRAn      Feedr\n",
       "979    980      Feedr       Norm\n",
       "986    987      Feedr       Norm\n",
       "991    992     Artery       Norm\n",
       "995    996      Feedr       Norm\n",
       "997    998       PosA       Norm\n",
       "1002  1003       RRAn       Norm\n",
       "1003  1004      Feedr       RRAn\n",
       "1006  1007       PosN       Norm\n",
       "1014  1015     Artery       Norm\n",
       "1026  1027      Feedr       Norm\n",
       "1028  1029     Artery       Norm\n",
       "1041  1042      Feedr       Norm\n",
       "1044  1045       PosN       Norm\n",
       "1052  1053     Artery       Norm\n",
       "1063  1064     Artery       Norm\n",
       "1071  1072       RRAn       Norm\n",
       "1072  1073     Artery       Norm\n",
       "1081  1082      Feedr       Norm\n",
       "1093  1094      Feedr       Norm\n",
       "\n",
       "[152 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(train_data['Condition1'] != 'Norm') |\n",
    "           (train_data['Condition2'] != 'Norm')]\\\n",
    "[['Id', 'Condition1', 'Condition2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this means that roughly 13% of the data, has nothing apart from 'Normal' condition.\n",
    "\n",
    "This brings into question , the effectiveness of a predictor built around this variable, as it is going to have one value for almost 87% of the data.\n",
    "\n",
    "Let us have another look at the number of cases when the conditions are listed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRNn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>PosA</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>183</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>207</td>\n",
       "      <td>RRAe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>223</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>RRNe</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>900</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>911</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>922</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>923</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>928</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>933</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>935</td>\n",
       "      <td>PosA</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>RRNn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>962</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>966</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>975</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Feedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>980</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>987</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>992</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>PosA</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1003</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1004</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>RRAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1015</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1027</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1029</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1042</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>1045</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1053</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1064</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>1072</td>\n",
       "      <td>RRAn</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1073</td>\n",
       "      <td>Artery</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1082</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1094</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Condition1 Condition2\n",
       "1        2      Feedr       Norm\n",
       "7        8       PosN       Norm\n",
       "8        9     Artery       Norm\n",
       "18      19       RRAe       Norm\n",
       "29      30      Feedr       RRNn\n",
       "30      31      Feedr       Norm\n",
       "52      53       RRNn       Norm\n",
       "60      61       RRAe       Norm\n",
       "63      64       RRAn      Feedr\n",
       "66      67       PosA       Norm\n",
       "68      69     Artery       Norm\n",
       "108    109     Artery       Norm\n",
       "127    128      Feedr       Norm\n",
       "128    129       PosN       Norm\n",
       "142    143     Artery       Norm\n",
       "144    145       RRAe       Norm\n",
       "155    156     Artery       Norm\n",
       "170    171      Feedr       Norm\n",
       "182    183     Artery       Norm\n",
       "184    185       RRAn      Feedr\n",
       "185    186     Artery       Norm\n",
       "188    189      Feedr       Norm\n",
       "197    198     Artery       Norm\n",
       "202    203     Artery       Norm\n",
       "206    207       RRAe       Norm\n",
       "222    223       RRAn       Norm\n",
       "228    229      Feedr       Norm\n",
       "237    238       RRNe       Norm\n",
       "260    261     Artery       Norm\n",
       "264    265     Artery       Norm\n",
       "...    ...        ...        ...\n",
       "899    900      Feedr       Norm\n",
       "910    911      Feedr       Norm\n",
       "921    922      Feedr       Norm\n",
       "922    923       RRAn       Norm\n",
       "927    928      Feedr       Norm\n",
       "932    933       RRNn       Norm\n",
       "934    935       PosA       Norm\n",
       "941    942       RRNn       Norm\n",
       "961    962       PosN       Norm\n",
       "965    966       RRAn       Norm\n",
       "974    975       RRAn      Feedr\n",
       "979    980      Feedr       Norm\n",
       "986    987      Feedr       Norm\n",
       "991    992     Artery       Norm\n",
       "995    996      Feedr       Norm\n",
       "997    998       PosA       Norm\n",
       "1002  1003       RRAn       Norm\n",
       "1003  1004      Feedr       RRAn\n",
       "1006  1007       PosN       Norm\n",
       "1014  1015     Artery       Norm\n",
       "1026  1027      Feedr       Norm\n",
       "1028  1029     Artery       Norm\n",
       "1041  1042      Feedr       Norm\n",
       "1044  1045       PosN       Norm\n",
       "1052  1053     Artery       Norm\n",
       "1063  1064     Artery       Norm\n",
       "1071  1072       RRAn       Norm\n",
       "1072  1073     Artery       Norm\n",
       "1081  1082      Feedr       Norm\n",
       "1093  1094      Feedr       Norm\n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Condition1'] != train_data['Condition2']][['Id', 'Condition1', 'Condition2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through all this, let us have a first stab at using this data. \n",
    "\n",
    "Let us start with a variable, that would simply add the norm conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test(train_data_one_hot, validation_data_one_hot, test_data_one_hot,\n",
    "                                       'Condition_Norm',\n",
    "                                       ['Condition1_Norm', 'Condition2_Norm'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_one_hot['Condition_Norm'] = train_data_one_hot['Condition_Norm'].apply(lambda x : np.bool(x))\n",
    "validation_data_one_hot['Condition_Norm'] = validation_data_one_hot['Condition_Norm'].apply(lambda x : np.bool(x))\n",
    "test_data_one_hot['Condition_Norm'] = test_data_one_hot['Condition_Norm'].apply(lambda x : np.bool(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1095\n",
       "unique       2\n",
       "top       True\n",
       "freq      1082\n",
       "Name: Condition_Norm, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_one_hot['Condition_Norm'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_one_hot['Condition_Norm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', \n",
    "              'MSSubClass_60_75_120_20', \n",
    "              'OverallQual', \n",
    "              'OverallCond', \n",
    "              'Neighborhood_Val', \n",
    "              'Condition_Norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16087865481119112\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)  \n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1627002604384478\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment : Okay, that is an encouragement. We do looking to be getting a boost here. The question is whether we can refine it further.\n",
    "\n",
    "This is the refined indicator which we propose :\n",
    "\n",
    "(i) For each value of the Condition variable, compute the average selling price for the cases when one of the variable (Condition1 or Condition2) is equal to the Condition Variable.\n",
    "(ii) Now, going over each record, do the following :\n",
    "\n",
    "    (a) Add the average log Sale price for each of the Conditions present in Condition1 and Condition 2 columns.\n",
    "    \n",
    "    \n",
    "This way, rather thna simply adding occurences, we add the mean average log Sale price , for each condition, which makes more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Norm', 'Feedr', 'PosN', 'Artery', 'RRAe', 'RRNn', 'RRAn', 'PosA',\n",
       "       'RRNe'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Condition1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Norm', 'Artery', 'RRNn', 'Feedr', 'PosN', 'PosA', 'RRAn'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Condition2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition_to_logSalePrice(train_data):\n",
    "    condition_to_logSalePrice = dict()\n",
    "    conditions = train_data['Condition1'].unique()\n",
    "    for condition in conditions:\n",
    "        #print(condition)\n",
    "        avg_logSalePrice = \\\n",
    "            train_data[\n",
    "                (train_data['Condition1'] == condition) | \n",
    "                (train_data['Condition2'] == condition) ]['LogSalePrice'].mean()\n",
    "        #print(avg_logSalePrice)\n",
    "        condition_to_logSalePrice[condition] = avg_logSalePrice\n",
    "    return condition_to_logSalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_to_logSalePrice = get_condition_to_logSalePrice(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Artery': 11.732441553254347,\n",
       " 'Feedr': 11.812712004906377,\n",
       " 'Norm': 12.027202075313038,\n",
       " 'PosA': 12.30290154907993,\n",
       " 'PosN': 12.226582648618214,\n",
       " 'RRAe': 11.825098630730913,\n",
       " 'RRAn': 12.017136649782707,\n",
       " 'RRNe': 12.15852566893868,\n",
       " 'RRNn': 11.864747799498494}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_to_logSalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conditions(condition_1, condition_2, condition_to_logSalePrice):\n",
    "    return (condition_to_logSalePrice.get(condition_1) + condition_to_logSalePrice.get(condition_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Condition_Val'] = train_data.apply(\n",
    "    lambda row: process_conditions(row['Condition1'],\n",
    "                                   row['Condition2'],\n",
    "                                   condition_to_logSalePrice), axis=1)\n",
    "validation_data['Condition_Val'] = validation_data.apply(\n",
    "    lambda row: process_conditions(row['Condition1'],\n",
    "                                   row['Condition2'],\n",
    "                                   condition_to_logSalePrice), axis=1)\n",
    "\n",
    "test_data['Condition_Val'] = test_data.apply(\n",
    "    lambda row: process_conditions(row['Condition1'],\n",
    "                                   row['Condition2'],\n",
    "                                   condition_to_logSalePrice), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_one_hot['Condition_Val'] = train_data['Condition_Val']\n",
    "validation_data_one_hot['Condition_Val'] = validation_data['Condition_Val']\n",
    "test_data_one_hot['Condition_Val'] = test_data['Condition_Val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x_cols = ['LogGrLivArea', \n",
    "              'MSSubClass_60_75_120_20', \n",
    "              'OverallQual', \n",
    "              'OverallCond', \n",
    "              'Neighborhood_Val', \n",
    "              'Condition_Val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16044332453739735\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_cross_validate( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16068525286452798\n"
     ]
    }
   ],
   "source": [
    "(my_pipeline, cross_validation_score) = fit_pipeline_and_evaluate_on_validation_set( \n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=rel_x_cols)\n",
    "print(cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can't we do better here ?\n",
    "\n",
    "This is a reasonable question and one needs to keep in mind that we are dealing with a variable that is having one value 87% of the same (both conditions are set to 'Norm'). So definitely, the predictive power will be limited.\n",
    "\n",
    "Hence, we are stopping on this for now, until new ideas dawn on me !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another idea ?\n",
    "\n",
    "In order to dril on more variables, shouldnt't it be better if have a normalized independent variable, say something like price per square feet , instead of square feet.\n",
    "\n",
    "One might claim that it should not matter since we have GrLivArea in the logarithmic scale itself as one of the predictors.However, this does affect the design of new variables and we have designed many of them using means of sale prices and it might have been more appropriate to design them using means of prices per square feet to get rid of the variability due to living area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_one_hot['LogSalePricePerSqFeet'] = train_data_one_hot['LogSalePrice'] - train_data_one_hot['LogGrLivArea']\n",
    "validation_data_one_hot['LogSalePricePerSqFeet'] = \\\n",
    "    validation_data_one_hot['LogSalePrice'] - validation_data_one_hot['LogGrLivArea']\n",
    "\n",
    "train_data['LogSalePricePerSqFeet'] = train_data['LogSalePrice'] - train_data['LogGrLivArea']\n",
    "validation_data['LogSalePricePerSqFeet'] = \\\n",
    "    validation_data['LogSalePrice'] - validation_data['LogGrLivArea']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with the first model.\n",
    "\n",
    "If all is well, this should identical results with the scenario when we used 'LogSalePrice' itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27161716540345976"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay , let us check if this holds up when we add another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23998906193907085"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25140820156722"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks fine, but let us see if we need another design for MSSubClass variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'MSSubClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>mean_LogSalePricePerSqFeet</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>68</td>\n",
       "      <td>198945.705882</td>\n",
       "      <td>12.166660</td>\n",
       "      <td>5.002448</td>\n",
       "      <td>6.210046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>15</td>\n",
       "      <td>151113.333333</td>\n",
       "      <td>11.918590</td>\n",
       "      <td>4.975857</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>403</td>\n",
       "      <td>184686.218362</td>\n",
       "      <td>12.048144</td>\n",
       "      <td>4.881947</td>\n",
       "      <td>36.803653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>7</td>\n",
       "      <td>92285.714286</td>\n",
       "      <td>11.407724</td>\n",
       "      <td>4.820376</td>\n",
       "      <td>0.639269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>38</td>\n",
       "      <td>168185.526316</td>\n",
       "      <td>12.009529</td>\n",
       "      <td>4.814403</td>\n",
       "      <td>3.470320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12</td>\n",
       "      <td>108591.666667</td>\n",
       "      <td>11.579033</td>\n",
       "      <td>4.807575</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>232</td>\n",
       "      <td>241847.021552</td>\n",
       "      <td>12.349193</td>\n",
       "      <td>4.764764</td>\n",
       "      <td>21.187215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50</td>\n",
       "      <td>95819.020000</td>\n",
       "      <td>11.436689</td>\n",
       "      <td>4.637016</td>\n",
       "      <td>4.566210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>49</td>\n",
       "      <td>138363.938776</td>\n",
       "      <td>11.804102</td>\n",
       "      <td>4.607860</td>\n",
       "      <td>4.474886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>11.671084</td>\n",
       "      <td>4.545775</td>\n",
       "      <td>0.273973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>41</td>\n",
       "      <td>166279.463415</td>\n",
       "      <td>11.949679</td>\n",
       "      <td>4.513621</td>\n",
       "      <td>3.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>140537.780000</td>\n",
       "      <td>11.800060</td>\n",
       "      <td>4.502164</td>\n",
       "      <td>9.132420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>39</td>\n",
       "      <td>133278.897436</td>\n",
       "      <td>11.779705</td>\n",
       "      <td>4.479923</td>\n",
       "      <td>3.561644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>24</td>\n",
       "      <td>130745.833333</td>\n",
       "      <td>11.743055</td>\n",
       "      <td>4.461907</td>\n",
       "      <td>2.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>14</td>\n",
       "      <td>200392.857143</td>\n",
       "      <td>12.099105</td>\n",
       "      <td>4.384461</td>\n",
       "      <td>1.278539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count  mean_SalePrice  mean_LogSalePrice  \\\n",
       "MSSubClass                                             \n",
       "120            68   198945.705882          12.166660   \n",
       "85             15   151113.333333          11.918590   \n",
       "20            403   184686.218362          12.048144   \n",
       "180             7    92285.714286          11.407724   \n",
       "80             38   168185.526316          12.009529   \n",
       "45             12   108591.666667          11.579033   \n",
       "60            232   241847.021552          12.349193   \n",
       "30             50    95819.020000          11.436689   \n",
       "160            49   138363.938776          11.804102   \n",
       "40              3   121500.000000          11.671084   \n",
       "70             41   166279.463415          11.949679   \n",
       "50            100   140537.780000          11.800060   \n",
       "90             39   133278.897436          11.779705   \n",
       "190            24   130745.833333          11.743055   \n",
       "75             14   200392.857143          12.099105   \n",
       "\n",
       "            mean_LogSalePricePerSqFeet  percent_total_size  \n",
       "MSSubClass                                                  \n",
       "120                           5.002448            6.210046  \n",
       "85                            4.975857            1.369863  \n",
       "20                            4.881947           36.803653  \n",
       "180                           4.820376            0.639269  \n",
       "80                            4.814403            3.470320  \n",
       "45                            4.807575            1.095890  \n",
       "60                            4.764764           21.187215  \n",
       "30                            4.637016            4.566210  \n",
       "160                           4.607860            4.474886  \n",
       "40                            4.545775            0.273973  \n",
       "70                            4.513621            3.744292  \n",
       "50                            4.502164            9.132420  \n",
       "90                            4.479923            3.561644  \n",
       "190                           4.461907            2.191781  \n",
       "75                            4.384461            1.278539  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_LogSalePricePerSqFeet'], ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>mean_LogSalePricePerSqFeet</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>232</td>\n",
       "      <td>241847.021552</td>\n",
       "      <td>12.349193</td>\n",
       "      <td>4.764764</td>\n",
       "      <td>21.187215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>68</td>\n",
       "      <td>198945.705882</td>\n",
       "      <td>12.166660</td>\n",
       "      <td>5.002448</td>\n",
       "      <td>6.210046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>14</td>\n",
       "      <td>200392.857143</td>\n",
       "      <td>12.099105</td>\n",
       "      <td>4.384461</td>\n",
       "      <td>1.278539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>403</td>\n",
       "      <td>184686.218362</td>\n",
       "      <td>12.048144</td>\n",
       "      <td>4.881947</td>\n",
       "      <td>36.803653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>38</td>\n",
       "      <td>168185.526316</td>\n",
       "      <td>12.009529</td>\n",
       "      <td>4.814403</td>\n",
       "      <td>3.470320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>41</td>\n",
       "      <td>166279.463415</td>\n",
       "      <td>11.949679</td>\n",
       "      <td>4.513621</td>\n",
       "      <td>3.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>15</td>\n",
       "      <td>151113.333333</td>\n",
       "      <td>11.918590</td>\n",
       "      <td>4.975857</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>49</td>\n",
       "      <td>138363.938776</td>\n",
       "      <td>11.804102</td>\n",
       "      <td>4.607860</td>\n",
       "      <td>4.474886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>140537.780000</td>\n",
       "      <td>11.800060</td>\n",
       "      <td>4.502164</td>\n",
       "      <td>9.132420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>39</td>\n",
       "      <td>133278.897436</td>\n",
       "      <td>11.779705</td>\n",
       "      <td>4.479923</td>\n",
       "      <td>3.561644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>24</td>\n",
       "      <td>130745.833333</td>\n",
       "      <td>11.743055</td>\n",
       "      <td>4.461907</td>\n",
       "      <td>2.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>11.671084</td>\n",
       "      <td>4.545775</td>\n",
       "      <td>0.273973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12</td>\n",
       "      <td>108591.666667</td>\n",
       "      <td>11.579033</td>\n",
       "      <td>4.807575</td>\n",
       "      <td>1.095890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50</td>\n",
       "      <td>95819.020000</td>\n",
       "      <td>11.436689</td>\n",
       "      <td>4.637016</td>\n",
       "      <td>4.566210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>7</td>\n",
       "      <td>92285.714286</td>\n",
       "      <td>11.407724</td>\n",
       "      <td>4.820376</td>\n",
       "      <td>0.639269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count  mean_SalePrice  mean_LogSalePrice  \\\n",
       "MSSubClass                                             \n",
       "60            232   241847.021552          12.349193   \n",
       "120            68   198945.705882          12.166660   \n",
       "75             14   200392.857143          12.099105   \n",
       "20            403   184686.218362          12.048144   \n",
       "80             38   168185.526316          12.009529   \n",
       "70             41   166279.463415          11.949679   \n",
       "85             15   151113.333333          11.918590   \n",
       "160            49   138363.938776          11.804102   \n",
       "50            100   140537.780000          11.800060   \n",
       "90             39   133278.897436          11.779705   \n",
       "190            24   130745.833333          11.743055   \n",
       "40              3   121500.000000          11.671084   \n",
       "45             12   108591.666667          11.579033   \n",
       "30             50    95819.020000          11.436689   \n",
       "180             7    92285.714286          11.407724   \n",
       "\n",
       "            mean_LogSalePricePerSqFeet  percent_total_size  \n",
       "MSSubClass                                                  \n",
       "60                            4.764764           21.187215  \n",
       "120                           5.002448            6.210046  \n",
       "75                            4.384461            1.278539  \n",
       "20                            4.881947           36.803653  \n",
       "80                            4.814403            3.470320  \n",
       "70                            4.513621            3.744292  \n",
       "85                            4.975857            1.369863  \n",
       "160                           4.607860            4.474886  \n",
       "50                            4.502164            9.132420  \n",
       "90                            4.479923            3.561644  \n",
       "190                           4.461907            2.191781  \n",
       "40                            4.545775            0.273973  \n",
       "45                            4.807575            1.095890  \n",
       "30                            4.637016            4.566210  \n",
       "180                           4.820376            0.639269  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_LogSalePrice'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values look slightly different here and we may want to do a redesign and see whether that helps. \n",
    "\n",
    "Let us add a map, like that we did for neighbourhood and see whether that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mssubclass_to_LogSalePricePerSquareFeet = dict(zip(results_df.index, results_df.mean_LogSalePricePerSqFeet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                 validation_data,\n",
    "                                                 test_data,\n",
    "                                                 train_data_one_hot,\n",
    "                                                 validation_data_one_hot,\n",
    "                                                 test_data_one_hot,\n",
    "                                                 'MSSubClass_Val',\n",
    "                                                 'MSSubClass',\n",
    "                                                 mssubclass_to_LogSalePricePerSquareFeet)                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21897039833536674"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks encouraging. Let us add OverallQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17554079176855364"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val', 'OverallQual'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18115854194021802"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_evaluate_on_validation_set(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    validation_data,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val', 'OverallQual'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look to be doing better than our earlier method, though it must be emphasized that this method of using means to quantify a categorical variable, works better on the training set than on the validation one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding OverallCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17214926002605713"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val', 'OverallQual', 'OverallCond'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17541842310833367"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_evaluate_on_validation_set(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    validation_data,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val', 'OverallQual', 'OverallCond'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add the key predictor of Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_mean_count_per_group(train_data, 'Neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>mean_SalePrice</th>\n",
       "      <th>mean_LogSalePrice</th>\n",
       "      <th>mean_LogSalePricePerSqFeet</th>\n",
       "      <th>percent_total_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StoneBr</th>\n",
       "      <td>22</td>\n",
       "      <td>320657.954545</td>\n",
       "      <td>12.617717</td>\n",
       "      <td>5.084896</td>\n",
       "      <td>2.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NridgHt</th>\n",
       "      <td>64</td>\n",
       "      <td>321781.359375</td>\n",
       "      <td>12.637217</td>\n",
       "      <td>5.081009</td>\n",
       "      <td>5.844749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veenker</th>\n",
       "      <td>8</td>\n",
       "      <td>240062.500000</td>\n",
       "      <td>12.340842</td>\n",
       "      <td>5.050478</td>\n",
       "      <td>0.730594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somerst</th>\n",
       "      <td>65</td>\n",
       "      <td>227413.692308</td>\n",
       "      <td>12.303509</td>\n",
       "      <td>4.938959</td>\n",
       "      <td>5.936073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timber</th>\n",
       "      <td>28</td>\n",
       "      <td>243325.964286</td>\n",
       "      <td>12.368274</td>\n",
       "      <td>4.930083</td>\n",
       "      <td>2.557078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blmngtn</th>\n",
       "      <td>14</td>\n",
       "      <td>194023.357143</td>\n",
       "      <td>12.165725</td>\n",
       "      <td>4.922987</td>\n",
       "      <td>1.278539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CollgCr</th>\n",
       "      <td>114</td>\n",
       "      <td>195479.008772</td>\n",
       "      <td>12.151860</td>\n",
       "      <td>4.908253</td>\n",
       "      <td>10.410959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoRidge</th>\n",
       "      <td>27</td>\n",
       "      <td>318553.333333</td>\n",
       "      <td>12.637571</td>\n",
       "      <td>4.862386</td>\n",
       "      <td>2.465753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>35</td>\n",
       "      <td>161726.742857</td>\n",
       "      <td>11.970940</td>\n",
       "      <td>4.806364</td>\n",
       "      <td>3.196347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClearCr</th>\n",
       "      <td>24</td>\n",
       "      <td>214159.666667</td>\n",
       "      <td>12.245548</td>\n",
       "      <td>4.805346</td>\n",
       "      <td>2.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sawyer</th>\n",
       "      <td>58</td>\n",
       "      <td>138805.741379</td>\n",
       "      <td>11.827806</td>\n",
       "      <td>4.766177</td>\n",
       "      <td>5.296804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>55</td>\n",
       "      <td>189854.527273</td>\n",
       "      <td>12.143467</td>\n",
       "      <td>4.764883</td>\n",
       "      <td>5.022831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SawyerW</th>\n",
       "      <td>48</td>\n",
       "      <td>185224.833333</td>\n",
       "      <td>12.080635</td>\n",
       "      <td>4.750543</td>\n",
       "      <td>4.383562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crawfor</th>\n",
       "      <td>34</td>\n",
       "      <td>199796.294118</td>\n",
       "      <td>12.156602</td>\n",
       "      <td>4.744032</td>\n",
       "      <td>3.105023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAmes</th>\n",
       "      <td>166</td>\n",
       "      <td>146291.072289</td>\n",
       "      <td>11.869944</td>\n",
       "      <td>4.738362</td>\n",
       "      <td>15.159817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPkVill</th>\n",
       "      <td>6</td>\n",
       "      <td>144500.000000</td>\n",
       "      <td>11.879205</td>\n",
       "      <td>4.723831</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWAmes</th>\n",
       "      <td>51</td>\n",
       "      <td>190841.274510</td>\n",
       "      <td>12.137510</td>\n",
       "      <td>4.706450</td>\n",
       "      <td>4.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrkSide</th>\n",
       "      <td>41</td>\n",
       "      <td>123731.097561</td>\n",
       "      <td>11.662072</td>\n",
       "      <td>4.649217</td>\n",
       "      <td>3.744292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blueste</th>\n",
       "      <td>2</td>\n",
       "      <td>137500.000000</td>\n",
       "      <td>11.826536</td>\n",
       "      <td>4.593893</td>\n",
       "      <td>0.182648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeadowV</th>\n",
       "      <td>15</td>\n",
       "      <td>97120.000000</td>\n",
       "      <td>11.459026</td>\n",
       "      <td>4.568534</td>\n",
       "      <td>1.369863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edwards</th>\n",
       "      <td>74</td>\n",
       "      <td>127836.486486</td>\n",
       "      <td>11.710861</td>\n",
       "      <td>4.565227</td>\n",
       "      <td>6.757991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrDale</th>\n",
       "      <td>11</td>\n",
       "      <td>104263.636364</td>\n",
       "      <td>11.546982</td>\n",
       "      <td>4.549308</td>\n",
       "      <td>1.004566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OldTown</th>\n",
       "      <td>85</td>\n",
       "      <td>128986.576471</td>\n",
       "      <td>11.702858</td>\n",
       "      <td>4.486638</td>\n",
       "      <td>7.762557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDOTRR</th>\n",
       "      <td>30</td>\n",
       "      <td>98809.333333</td>\n",
       "      <td>11.429113</td>\n",
       "      <td>4.412624</td>\n",
       "      <td>2.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWISU</th>\n",
       "      <td>18</td>\n",
       "      <td>147407.444444</td>\n",
       "      <td>11.885204</td>\n",
       "      <td>4.401300</td>\n",
       "      <td>1.643836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  mean_SalePrice  mean_LogSalePrice  \\\n",
       "Neighborhood                                             \n",
       "StoneBr          22   320657.954545          12.617717   \n",
       "NridgHt          64   321781.359375          12.637217   \n",
       "Veenker           8   240062.500000          12.340842   \n",
       "Somerst          65   227413.692308          12.303509   \n",
       "Timber           28   243325.964286          12.368274   \n",
       "Blmngtn          14   194023.357143          12.165725   \n",
       "CollgCr         114   195479.008772          12.151860   \n",
       "NoRidge          27   318553.333333          12.637571   \n",
       "Mitchel          35   161726.742857          11.970940   \n",
       "ClearCr          24   214159.666667          12.245548   \n",
       "Sawyer           58   138805.741379          11.827806   \n",
       "Gilbert          55   189854.527273          12.143467   \n",
       "SawyerW          48   185224.833333          12.080635   \n",
       "Crawfor          34   199796.294118          12.156602   \n",
       "NAmes           166   146291.072289          11.869944   \n",
       "NPkVill           6   144500.000000          11.879205   \n",
       "NWAmes           51   190841.274510          12.137510   \n",
       "BrkSide          41   123731.097561          11.662072   \n",
       "Blueste           2   137500.000000          11.826536   \n",
       "MeadowV          15    97120.000000          11.459026   \n",
       "Edwards          74   127836.486486          11.710861   \n",
       "BrDale           11   104263.636364          11.546982   \n",
       "OldTown          85   128986.576471          11.702858   \n",
       "IDOTRR           30    98809.333333          11.429113   \n",
       "SWISU            18   147407.444444          11.885204   \n",
       "\n",
       "              mean_LogSalePricePerSqFeet  percent_total_size  \n",
       "Neighborhood                                                  \n",
       "StoneBr                         5.084896            2.009132  \n",
       "NridgHt                         5.081009            5.844749  \n",
       "Veenker                         5.050478            0.730594  \n",
       "Somerst                         4.938959            5.936073  \n",
       "Timber                          4.930083            2.557078  \n",
       "Blmngtn                         4.922987            1.278539  \n",
       "CollgCr                         4.908253           10.410959  \n",
       "NoRidge                         4.862386            2.465753  \n",
       "Mitchel                         4.806364            3.196347  \n",
       "ClearCr                         4.805346            2.191781  \n",
       "Sawyer                          4.766177            5.296804  \n",
       "Gilbert                         4.764883            5.022831  \n",
       "SawyerW                         4.750543            4.383562  \n",
       "Crawfor                         4.744032            3.105023  \n",
       "NAmes                           4.738362           15.159817  \n",
       "NPkVill                         4.723831            0.547945  \n",
       "NWAmes                          4.706450            4.657534  \n",
       "BrkSide                         4.649217            3.744292  \n",
       "Blueste                         4.593893            0.182648  \n",
       "MeadowV                         4.568534            1.369863  \n",
       "Edwards                         4.565227            6.757991  \n",
       "BrDale                          4.549308            1.004566  \n",
       "OldTown                         4.486638            7.762557  \n",
       "IDOTRR                          4.412624            2.739726  \n",
       "SWISU                           4.401300            1.643836  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(['mean_LogSalePricePerSqFeet'], ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_to_LogSalePricePerSquareFeet = dict(zip(results_df.index, results_df.mean_LogSalePricePerSqFeet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test_from_dict(train_data,\n",
    "                                                 validation_data,\n",
    "                                                 test_data,\n",
    "                                                 train_data_one_hot,\n",
    "                                                 validation_data_one_hot,\n",
    "                                                 test_data_one_hot,\n",
    "                                                 'Neighborhood_new_Val',\n",
    "                                                 'Neighborhood',\n",
    "                                                 neighborhood_to_LogSalePricePerSquareFeet)                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15503440366046023"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val', 'OverallQual', 'OverallCond', 'Neighborhood_new_Val'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16270112741137843"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_evaluate_on_validation_set(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    validation_data,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass_Val', 'OverallQual', 'OverallCond', 'Neighborhood_new_Val'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting while doing cross validation.\n",
    "\n",
    "This once again highlights the issue of us overfitting on the training set, since we use mean values from the set itself while designing predictors.\n",
    "\n",
    "Though, we are somehow 'insured' against dangerous overfitting by the presence of a validation set, it would still be better if we were to have a clear cross validation procedure which took this into account(that is, during every round of cross validation, it would take mean of the values in the training set and apply them to predict values in the validation set, preventing overfitting).\n",
    "\n",
    "Another thing which remains to be tested is how the results standard when we properly randomize training and validation sets (we should have done this here, but did not do it !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15585270045871383"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_cross_validate(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    X_columns=['LogGrLivArea', \n",
    "               'MSSubClass_Val', \n",
    "               'OverallQual', \n",
    "               'OverallCond', \n",
    "               'Neighborhood_Val'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15604738233645235"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_pipeline_and_evaluate_on_validation_set(\n",
    "    make_pipeline(Imputer(), linear_model.LinearRegression()), \n",
    "    train_data, \n",
    "    validation_data,\n",
    "    X_columns=['LogGrLivArea', \n",
    "               'MSSubClass_Val', \n",
    "               'OverallQual', \n",
    "               'OverallCond', \n",
    "               'Neighborhood_Val'],\n",
    "    Y_column='LogSalePricePerSqFeet')[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is echoes the point which we had made earlier. We have this weird set of predictors with MSSubClass classified according to price per square feet and Neighbourhood classified according to price and all these work well together.\n",
    "\n",
    "Before we proceed any more on designing new predictors , we need to do the following :\n",
    "\n",
    "1. Write up a thorough cross validaiton routine. When I say thorough, what I mean is that we should be able to test out features, which use mean of prices etc., within the cross validation routine. These features are really tricky, and it would be really difficult to judge them without doing a thorough cross validation.\n",
    "\n",
    "2. Repeat the tests with randomized input data. This should have done earlier. This is because it is easy to us to end up with a nice training set and end up training the model only on the same. Randomization would ensure that model works on other input data as well and hence increase robustness of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thorough routine for doing cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_transformation(train_data, validation_data):\n",
    "    train_data['LogGrLivArea_Val'] = train_data['LogGrLivArea']\n",
    "    validation_data['LogGrLivArea_Val'] = validation_data['LogGrLivArea']    \n",
    "    return 'LogGrLivArea_Val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSSubClass_indicator_transformation(train_data, validation_data):\n",
    "    train_data['MSSubClass_60_75_120_20'] = train_data['MSSubClass_120'] + \\\n",
    "    train_data['MSSubClass_60'] + train_data['MSSubClass_20'] + train_data['MSSubClass_75'] \n",
    "    validation_data['MSSubClass_60_75_120_20'] = validation_data['MSSubClass_120'] + \\\n",
    "    validation_data['MSSubClass_60'] + validation_data['MSSubClass_20'] + validation_data['MSSubClass_75']\n",
    "    return 'MSSubClass_60_75_120_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_output(input_df, X_columns=['LogGrLivArea'], X_column_transform_map={}, Y_column = 'LogSalePricePerSqFeet', nfolds=5):\n",
    "    partition_indices = np.array_split(np.arange(len(input_df)), nfolds)\n",
    "    \n",
    "    cross_validated_scores = np.zeros(nfolds)\n",
    "    cross_validated_data = pd.DataFrame(columns=input_df.columns)\n",
    "    for i in range(nfolds):\n",
    "        cross_validated_set = input_df[partition_indices[i][0]:partition_indices[i][-1] + 1].copy()\n",
    "        rel_training_data = pd.DataFrame(columns=input_df.columns)\n",
    "        for j in range(nfolds):\n",
    "            if j != i:\n",
    "                training_set = input_df[partition_indices[j][0]:partition_indices[j][-1] + 1]\n",
    "                rel_training_data = pd.concat([rel_training_data, training_set])\n",
    "\n",
    "        \n",
    "        rel_X_cols = list()\n",
    "        for col in X_columns:\n",
    "            if col in X_column_transform_map.keys():\n",
    "                rel_col = X_column_transform_map.get(col)(rel_training_data, cross_validated_set)\n",
    "            else:\n",
    "                rel_col = col\n",
    "            rel_X_cols.append(rel_col)\n",
    "        X = rel_training_data[rel_X_cols]\n",
    "        Y = rel_training_data[[Y_column]].values.ravel()\n",
    "        my_model = linear_model.LinearRegression()\n",
    "        my_model.fit(X,Y)\n",
    "        newX = cross_validated_set[rel_X_cols]\n",
    "        newY = cross_validated_set[[Y_column]]\n",
    "        cross_validated_score = evaluate_model_score(my_model, newX, newY)\n",
    "        cross_validated_scores[i] = cross_validated_score\n",
    "        \n",
    "    return cross_validated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26563421 0.25911464 0.27404988 0.27610276 0.28318435]\n",
      "0.27161716540345976\n",
      "0.00838984347419547\n"
     ]
    }
   ],
   "source": [
    "cross_validation_scores = get_cross_val_output(train_data)\n",
    "print(cross_validation_scores)\n",
    "print(cross_validation_scores.mean())\n",
    "print(cross_validation_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how things look after the addition of our initial MSSubClass variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_column_train_validation_test(train_data_one_hot, validation_data_one_hot, test_data_one_hot,\n",
    "                                      'MSSubClass_60_75_120_20', \n",
    "                                      ['MSSubClass_120', 'MSSubClass_60', 'MSSubClass_20', 'MSSubClass_75'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2299178  0.22909246 0.24402261 0.24979964 0.24711279]\n",
      "0.23998906193907085\n",
      "0.008757063005795292\n"
     ]
    }
   ],
   "source": [
    "cross_validation_scores = get_cross_val_output(train_data_one_hot, X_columns=['LogGrLivArea', 'MSSubClass_60_75_120_20'])\n",
    "print(cross_validation_scores)\n",
    "print(cross_validation_scores.mean())\n",
    "print(cross_validation_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, comes the real tricky part where we use grouped means to get a quantified version of the variable. Let us see how to get it !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2299178  0.22909246 0.24402261 0.24979964 0.24711279]\n",
      "0.23998906193907085\n",
      "0.008757063005795292\n"
     ]
    }
   ],
   "source": [
    "cross_validation_scores = get_cross_val_output(\n",
    "    train_data_one_hot, \n",
    "    X_columns=['LogGrLivArea', 'MSSubClass'],\n",
    "    X_column_transform_map={'MSSubClass' : get_MSSubClass_indicator_transformation})\n",
    "print(cross_validation_scores)\n",
    "print(cross_validation_scores.mean())\n",
    "print(cross_validation_scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks great, now let us make sure that we can get a validation score on a validation set also easily by writing a routine that is almost identical to the one written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_output(input_df, validation_df, X_columns=['LogGrLivArea'], X_column_transform_map={}, Y_column = 'LogSalePricePerSqFeet', nfolds=5):\n",
    "    rel_X_cols = list()\n",
    "    for col in X_columns:\n",
    "        if col in X_column_transform_map.keys():\n",
    "            rel_col = X_column_transform_map.get(col)(input_df, validation_df)\n",
    "        else:\n",
    "            rel_col = col\n",
    "        rel_X_cols.append(rel_col)\n",
    "    X = input_df[rel_X_cols]\n",
    "    Y = input_df[[Y_column]].values.ravel()\n",
    "    my_model = linear_model.LinearRegression()\n",
    "    my_model.fit(X,Y)\n",
    "    newX = validation_df[rel_X_cols]\n",
    "    newY = validation_df[[Y_column]]\n",
    "    cross_validated_score = evaluate_model_score(my_model, newX, newY)\n",
    "        \n",
    "    return cross_validated_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23849795274552374\n"
     ]
    }
   ],
   "source": [
    "validation_score = get_validation_output(\n",
    "    train_data_one_hot, \n",
    "    validation_data_one_hot,\n",
    "    X_columns=['LogGrLivArea', 'MSSubClass'],\n",
    "    X_column_transform_map={'MSSubClass' : get_MSSubClass_indicator_transformation})\n",
    "print(validation_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us make sure that we can make predictions on test data as well (applying the same transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_predictions(input_df, test_df, X_columns=['LogGrLivArea'], X_column_transform_map={}, Y_column = 'LogSalePricePerSqFeet', nfolds=5):\n",
    "    rel_X_cols = list()\n",
    "    for col in X_columns:\n",
    "        if col in X_column_transform_map.keys():\n",
    "            rel_col = X_column_transform_map.get(col)(input_df, test_df)\n",
    "        else:\n",
    "            rel_col = col\n",
    "        rel_X_cols.append(rel_col)\n",
    "    X = input_df[rel_X_cols]\n",
    "    Y = input_df[[Y_column]].values.ravel()\n",
    "    my_model = linear_model.LinearRegression()\n",
    "    my_model.fit(X,Y)\n",
    "    newX = test_df[rel_X_cols]\n",
    "    predicitons =  my_model.predict(newX)\n",
    "        \n",
    "    return predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_living_area(train_data, validation_data):\n",
    "    train_data['LogGrLivArea'] = train_data['GrLivArea'].apply(lambda x : np.log(1.0 + x))\n",
    "    validation_data['LogGrLivArea'] = validation_data['GrLivArea'].apply(lambda x : np.log(1.0 + x))\n",
    "    return 'LogGrLivArea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103138.07938093, 168398.91942366, 202099.99630156, ...,\n",
       "       154773.06959036, 116272.25198311, 236077.10379031])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_data_predictions(complete_train_data, \n",
    "                          test_data, \n",
    "                          X_columns=['GrLivArea'], \n",
    "                          X_column_transform_map = {'GrLivArea' : log_transform_living_area},\n",
    "                          Y_column = 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is great. Now let us just redefine the functions, modularizing common code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_X_cols(input_df, validation_df, X_columns, X_column_transform_map):\n",
    "    rel_X_cols = list()\n",
    "    for col in X_columns:\n",
    "        if col in X_column_transform_map.keys():\n",
    "            rel_col = X_column_transform_map.get(col)(input_df, validation_df)\n",
    "        else:\n",
    "            rel_col = col\n",
    "        rel_X_cols.append(rel_col)\n",
    "    return rel_X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(X, Y):\n",
    "    my_model = linear_model.LinearRegression()\n",
    "    my_model.fit(X,Y)\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_output(input_df, X_columns=['LogGrLivArea'], X_column_transform_map={}, Y_column = 'LogSalePricePerSqFeet', nfolds=5):\n",
    "    partition_indices = np.array_split(np.arange(len(input_df)), nfolds)\n",
    "    \n",
    "    cross_validated_scores = np.zeros(nfolds)\n",
    "    cross_validated_data = pd.DataFrame(columns=input_df.columns)\n",
    "    for i in range(nfolds):\n",
    "        cross_validated_set = input_df[partition_indices[i][0]:partition_indices[i][-1] + 1].copy()\n",
    "        rel_training_data = pd.DataFrame(columns=input_df.columns)\n",
    "        for j in range(nfolds):\n",
    "            if j != i:\n",
    "                training_set = input_df[partition_indices[j][0]:partition_indices[j][-1] + 1]\n",
    "                rel_training_data = pd.concat([rel_training_data, training_set])\n",
    "\n",
    "        \n",
    "        rel_X_cols = get_rel_X_cols(rel_training_data, cross_validated_set, X_columns, X_column_transform_map)\n",
    "        my_model = get_trained_model(rel_training_data[rel_X_cols], \n",
    "                                     rel_training_data[[Y_column]].values.ravel())\n",
    "        newX = cross_validated_set[rel_X_cols]\n",
    "        newY = cross_validated_set[[Y_column]]\n",
    "        cross_validated_score = evaluate_model_score(my_model, newX, newY)\n",
    "        cross_validated_scores[i] = cross_validated_score\n",
    "        \n",
    "    return cross_validated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_output(input_df, validation_df, X_columns=['LogGrLivArea'], X_column_transform_map={}, Y_column = 'LogSalePricePerSqFeet', nfolds=5):\n",
    "    rel_X_cols = get_rel_X_cols(input_df, validation_df, X_columns, X_column_transform_map)\n",
    "    my_model = get_trained_model(input_df[rel_X_cols], \n",
    "                                 input_df[[Y_column]].values.ravel())\n",
    "\n",
    "    newX = validation_df[rel_X_cols]\n",
    "    newY = validation_df[[Y_column]]\n",
    "    cross_validated_score = evaluate_model_score(my_model, newX, newY)\n",
    "        \n",
    "    return cross_validated_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_predictions(input_df, test_df, X_columns=['LogGrLivArea'], X_column_transform_map={}, Y_column = 'LogSalePricePerSqFeet', nfolds=5):\n",
    "    rel_X_cols = get_rel_X_cols(input_df, test_df, X_columns, X_column_transform_map)        \n",
    "    my_model = get_trained_model(input_df[rel_X_cols], \n",
    "                                 input_df[[Y_column]].values.ravel())\n",
    "    \n",
    "    newX = test_df[rel_X_cols]\n",
    "    predicitons =  my_model.predict(newX)\n",
    "        \n",
    "    return predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are all set now. Let us continue the rest in a new notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
